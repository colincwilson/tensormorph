{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, sys\n",
    "import pylangacq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pylangacq.read_chat('/Users/colin/Downloads/Ornat/010700b.cha')\n",
    "dat = dat.tagged_sents(by_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('quemó', 'quema') --> ('quema', 'quema')\n",
      "('se', 'se') --> ('es', 'se')\n",
      "('es', 'se') --> ('se', 'se')\n",
      "('quema', 'quema') --> ('quemó', 'quema')\n",
      "('es', 'se') --> ('se', 'se')\n",
      "('quema', 'quema') --> ('quemó', 'quema')\n",
      "('tapar', 'tapa') --> ('tapamos', 'tapa')\n",
      "('la', 'el') --> ('las', 'el')\n",
      "('las', 'el') --> ('la', 'el')\n",
      "('0a', 'a') --> ('a', 'a')\n",
      "('a', 'a') --> ('0a', 'a')\n",
      "('los', 'el') --> ('el', 'el')\n",
      "('el', 'el') --> ('las', 'el')\n",
      "('piernecitas', 'pierna') --> ('piernas', 'pierna')\n",
      "('este', 'este') --> ('esta', 'este')\n",
      "('esta', 'este') --> ('este', 'este')\n",
      "('de', 'de') --> ('del', 'de')\n",
      "('del', 'de') --> ('de', 'de')\n",
      "('CLITIC', 'el') --> ('la', 'el')\n",
      "('CLITIC', 'el') --> ('la', 'el')\n",
      "('está', 'esta') --> ('estás', 'esta')\n",
      "('está', 'esta') --> ('estás', 'esta')\n",
      "('está', 'esta') --> ('estás', 'esta')\n",
      "('está', 'esta') --> ('estás', 'esta')\n",
      "('esperes', 'espera') --> ('espero', 'espera')\n",
      "('dice', 'deci') --> ('decírmelo', 'deci')\n",
      "('⌊María⌋', 'María') --> ('María', 'María')\n",
      "('el', 'el') --> ('la', 'el')\n",
      "('las', 'el') --> ('la', 'el')\n",
      "('el', 'el') --> ('las', 'el')\n",
      "('la', 'el') --> ('las', 'el')\n",
      "('CLITIC', '') --> ('⌈&=miraMamá⌉', '')\n",
      "('.', '') --> ('⌈&=miraMamá⌉', '')\n",
      "('.', '') --> ('⌈&=miraMamá⌉', '')\n",
      "('⌈&=miraMamá⌉', '') --> ('⌊&=canta⌋', '')\n",
      "('.', '') --> ('⌊&=canta⌋', '')\n",
      "('.', '') --> ('⌊&=canta⌋', '')\n",
      "('haciendo', 'hace') --> ('hacer', 'hace')\n",
      "('están', 'esta') --> ('está', 'esta')\n",
      "('está', 'esta') --> ('están', 'esta')\n",
      "('la', 'el') --> ('los', 'el')\n",
      "('los', 'el') --> ('la', 'el')\n",
      "('los', 'el') --> ('la', 'el')\n",
      "('dile', 'deci') --> ('dí', 'deci')\n",
      "('es', 'se') --> ('eres', 'se')\n",
      "('dí', 'deci') --> ('dile', 'deci')\n",
      "('eres', 'se') --> ('es', 'se')\n",
      "('eres', 'se') --> ('es', 'se')\n",
      "('es', 'se') --> ('era', 'se')\n",
      "('el', 'el') --> ('la', 'el')\n",
      "('la', 'el') --> ('los', 'el')\n",
      "('los', 'el') --> ('el', 'el')\n",
      "('los', 'el') --> ('el', 'el')\n",
      "('el', 'el') --> ('los', 'el')\n",
      "('el', 'el') --> ('los', 'el')\n",
      "('los', 'el') --> ('el', 'el')\n",
      "('los', 'el') --> ('el', 'el')\n",
      "('dilo', 'deci') --> ('di', 'deci')\n",
      "('di', 'deci') --> ('dilo', 'deci')\n",
      "('CLITIC', 'el') --> ('las', 'el')\n",
      "('tiene', 'tene') --> ('tienes', 'tene')\n",
      "('los', 'el') --> ('el', 'el')\n",
      "('los', 'el') --> ('el', 'el')\n",
      "('el', 'el') --> ('los', 'el')\n",
      "('el', 'el') --> ('las', 'el')\n",
      "('los', 'el') --> ('las', 'el')\n",
      "('los', 'el') --> ('las', 'el')\n",
      "('los', 'el') --> ('las', 'el')\n",
      "('la', 'el') --> ('las', 'el')\n",
      "('las', 'el') --> ('los', 'el')\n",
      "('las', 'el') --> ('los', 'el')\n",
      "('la', 'el') --> ('los', 'el')\n",
      "('las', 'el') --> ('los', 'el')\n",
      "('las', 'el') --> ('los', 'el')\n",
      "('la', 'el') --> ('los', 'el')\n",
      "('están', 'esta') --> ('estar', 'esta')\n",
      "('las', 'el') --> ('la', 'el')\n",
      "('las', 'el') --> ('la', 'el')\n",
      "('los', 'el') --> ('la', 'el')\n",
      "('los', 'el') --> ('la', 'el')\n",
      "('botas', 'bota') --> ('bota', 'bota')\n",
      "('estar', 'esta') --> ('está', 'esta')\n",
      "('la', 'el') --> ('los', 'el')\n",
      "('beso', 'beso') --> ('besito', 'beso')\n"
     ]
    }
   ],
   "source": [
    "# Add stem information\n",
    "for key,sents in dat.items():\n",
    "    for sent in sents:\n",
    "        for i,token in enumerate(sent):\n",
    "            form, pos, mor = token[0:3]\n",
    "            stem = re.sub('[&-=].*', '', mor)\n",
    "            sent[i] = (form, pos, mor, stem)\n",
    "            #print(sent[i])\n",
    "\n",
    "# Search for repeated stems within a window\n",
    "k = 2 # Window size (number of previous utterances)\n",
    "for key,sents in dat.items():\n",
    "    for i in range(k,len(sents)):\n",
    "        sents_prev = sents[(i-k):i]\n",
    "        words_stems_prev = []\n",
    "        for sent in sents_prev:\n",
    "            words_stems_prev += [(token[0], token[3]) for token in sent]\n",
    "        words_stems = [(token[0], token[3]) for token in sent]\n",
    "        for token in words_stems:\n",
    "            if re.search('[?!.]', token[0]):\n",
    "                continue\n",
    "            if re.search('CLITIC', token[0]):\n",
    "                continue\n",
    "            for token_prev in words_stems_prev:\n",
    "                if token[1]==token_prev[1] and token[0]!=token_prev[0]:\n",
    "                    print(token_prev, '-->', token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
